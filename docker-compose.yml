# =============================================================================
# Docker Compose para ARIA Demo (TensorRT)
# =============================================================================
#
# Uso:
#   docker compose up              # Iniciar (primera vez hace build)
#   docker compose up --build      # Reconstruir imagen
#   docker compose down            # Parar y limpiar
#   docker compose up -d           # Iniciar en background
#   docker compose logs -f         # Ver logs en tiempo real
#
# Acceso:
#   Dashboard: http://localhost:5000
#
# =============================================================================

services:
  aria-demo:
    image: aria-demo:tensorrt
    container_name: aria-demo

    # Modo privilegiado: necesario para acceso completo a USB
    # Requerido por Aria SDK para comunicacion con las gafas
    privileged: true

    # Puerto del dashboard web
    ports:
      - "5000:5000"

    volumes:
      # USB passthrough para conectar Aria glasses
      - /dev/bus/usb:/dev/bus/usb
      # Directorio de datos compartido (videos, datasets VRS)
      - ./data:/app/data
      # Modelos (TensorRT engines, ONNX, weights)
      - ./models:/app/models
      # CÃ³digo fuente (para desarrollo sin rebuild)
      - ./run.py:/app/run.py:ro
      - ./src:/app/src:ro
      - ./scripts:/app/scripts:ro
      # PulseAudio socket para audio output
      - /run/user/1000/pulse:/run/user/1000/pulse:ro
      - ~/.config/pulse/cookie:/root/.config/pulse/cookie:ro

    devices:
      # Audio para text-to-speech (espeak-ng)
      - /dev/snd:/dev/snd
      # Webcam (si se usa)
      - /dev/video0:/dev/video0

    environment:
      # Display para aplicaciones GUI (si se necesita)
      - DISPLAY=${DISPLAY}
      # GPU access for CUDA in child processes
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
      # PulseAudio para audio output
      - PULSE_SERVER=unix:/run/user/1000/pulse/native

    # Terminal interactiva (para menu de seleccion)
    stdin_open: true
    tty: true

    # Acceso a GPU NVIDIA para inferencia de modelos
    # Requiere nvidia-container-toolkit instalado en el host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    # Comando por defecto: ejecutar la aplicacion
    command: python run.py
